{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SiuDanny_HW_4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5KTrLJKD-l7",
        "colab_type": "text"
      },
      "source": [
        "# Homework 4: Neural Sequence Labeling\n",
        "\n",
        "**Due March 4, 2020 at 11:59PM**\n",
        "\n",
        "\n",
        "In this homework, you will be implementing, training, and evaluating an LSTM for part-of-speech tagging using the PyTorch library."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFgEH9BWEqPV",
        "colab_type": "text"
      },
      "source": [
        "**Before beginning, please switch your Colab session to a GPU runtime** \n",
        "\n",
        "Go to Runtime > Change runtime type > Hardware accelerator > GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xALTxzWIEkkE",
        "colab_type": "text"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kk8GRWIkbrU1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import libraries\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pad_sequence, pad_packed_sequence, pack_padded_sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t87Vex5_b5MI",
        "colab_type": "code",
        "outputId": "c1b45f89-b562-43c3-b847-02aa7b96929b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# if this cell prints \"Running on cpu\", you must switch runtime environments\n",
        "# go to Runtime > Change runtime type > Hardware accelerator > GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Running on {}\".format(device))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running on cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3nDS9MwFCVf",
        "colab_type": "text"
      },
      "source": [
        "### Download & Load Pretrained Embeddings\n",
        "\n",
        "In this assignment, we will be using GloVe pretrained word embeddings. You can read more about GloVe here: https://nlp.stanford.edu/projects/glove/\n",
        "\n",
        "**Note**: this section will take *several minutes*, since the embedding files are large. Files in Colab may be cached between sessions, so you may or may not need to redownload the files each time you reconnect. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csWld6ckFNL1",
        "colab_type": "code",
        "outputId": "8c3439be-0676-4be9-a26c-56ae2f45d9bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        }
      },
      "source": [
        "# download pretrained word embeddings\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove*.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-06 00:30:40--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2020-03-06 00:30:45--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2020-03-06 00:30:46--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  1.92MB/s    in 6m 30s  \n",
            "\n",
            "2020-03-06 00:37:16 (2.11 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiuJ5eylL0A0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_embeddings(filename, vocab_size=10000):\n",
        "  \"\"\"\n",
        "  Utility function, loads in the `vocab_size` most common embeddings from `filename`\n",
        "  \n",
        "  Arguments:\n",
        "  - filename:     path to file\n",
        "                  automatically infers correct embedding dimension from filename\n",
        "  - vocab_size:   maximum number of embeddings to load\n",
        "\n",
        "  Returns \n",
        "  - embeddings:   torch.FloatTensor matrix of size (vocab_size x word_embedding_dim)\n",
        "  - vocab:        dictionary mapping word (str) to index (int) in embedding matrix\n",
        "  \"\"\"\n",
        "\n",
        "  # get the embedding size from the first embedding\n",
        "  with open(filename, encoding=\"utf-8\") as file:\n",
        "    word_embedding_dim = len(file.readline().split(\" \")) - 1\n",
        "\n",
        "  vocab = {}\n",
        "\n",
        "  embeddings = np.zeros((vocab_size, word_embedding_dim))\n",
        "\n",
        "  with open(filename, encoding=\"utf-8\") as file:\n",
        "    for idx, line in enumerate(file):\n",
        "\n",
        "      if idx + 2 >= vocab_size:\n",
        "        break\n",
        "\n",
        "      cols = line.rstrip().split(\" \")\n",
        "      val = np.array(cols[1:])\n",
        "      word = cols[0]\n",
        "      embeddings[idx + 2] = val\n",
        "      vocab[word] = idx + 2\n",
        "  \n",
        "  # a FloatTensor is a multidimensional matrix\n",
        "  # that contains 32-bit floats in every entry\n",
        "  # https://pytorch.org/docs/stable/tensors.html\n",
        "  return torch.FloatTensor(embeddings), vocab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ah3clY7lHNZ",
        "colab_type": "text"
      },
      "source": [
        "Running the cell below lists all the files in the current directory. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4D__oK6mQ6hs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "f97fa615-949d-4eea-fd79-2061c69aa839"
      },
      "source": [
        "!ls -lh"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 2.9G\n",
            "-rw-rw-r-- 1 root root 332M Aug  4  2014 glove.6B.100d.txt\n",
            "-rw-rw-r-- 1 root root 662M Aug  4  2014 glove.6B.200d.txt\n",
            "-rw-rw-r-- 1 root root 990M Aug 27  2014 glove.6B.300d.txt\n",
            "-rw-rw-r-- 1 root root 164M Aug  4  2014 glove.6B.50d.txt\n",
            "-rw-r--r-- 1 root root 823M Oct 25  2015 glove.6B.zip\n",
            "drwxr-xr-x 1 root root 4.0K Mar  3 18:11 sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoSWrCwZllg6",
        "colab_type": "text"
      },
      "source": [
        "You should see several embedding files, which are all formatted as\n",
        "\n",
        "```\n",
        "glove.6B.<emb_dim>d.txt\n",
        "```\n",
        "\n",
        "Each `txt` file contains `emb_dim` dimensional embeddings for 400,000 unique, uncased words. The script below loads the `vocab_size` most common words from the embedding file into a matrix we can give to our model. All other words will later be mapped to the `UNKNOWN` embedding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xL8WuEZoOFbs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this loads the 10,000 most common word 50-dimensional embeddings\n",
        "vocab_size = 10000\n",
        "embeddings, vocab = read_embeddings('glove.6B.50d.txt', vocab_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "py9AStUOJnPB",
        "colab_type": "text"
      },
      "source": [
        "## Part 1: Batching the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5jWl-z8w_5t",
        "colab_type": "text"
      },
      "source": [
        "Implement the `get_batches` function in the `Dataset` class below. \n",
        "\n",
        "**Please make sure that**\n",
        "\n",
        "*   Your implementation is self-contained. That is, all helper functions and variables are defined within `get_batches`.\n",
        "*   Your implementation can handle variable batch sizes. You may not assume that the value with always be 32\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KWyqb2HcLop",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Dataset():\n",
        "  def __init__(self, filename, is_labeled):\n",
        "    self.is_labeled = is_labeled\n",
        "    # if the file is not labeled, the Dataset has no tags (see read_data)\n",
        "    if is_labeled:\n",
        "      self.sentences, self.tags = self.read_data(filename, is_labeled)\n",
        "    else:\n",
        "      self.sentences = self.read_data(filename, is_labeled)\n",
        "      self.tags = None\n",
        "\n",
        "  def read_data(self, filename, is_labeled):\n",
        "    \"\"\"\n",
        "    Utility function, loads text file into a list of sentence and tag strings\n",
        "\n",
        "    Arguments:\n",
        "    - filename:     path to file\n",
        "    - is_labeled:   whether the file contains tags for each word or not\n",
        "        > if True, we assume each line is formatted as \"<word>\\t<tag>\\n\"\n",
        "        > if False, we assume each line is formatted as \"<word>\\n\"\n",
        "\n",
        "    Returns:\n",
        "    - sentences:    a list of sentences, where each sentence is a list \n",
        "                    words (strings)\n",
        "\n",
        "    if is_labeled=True, also returns\n",
        "    - tags:         a list of tags for each sentence, where tags[i] contains\n",
        "                    a list of tags (strings) that correspond to the words in \n",
        "                    sentences[i]\n",
        "    \"\"\"\n",
        "    sentences = []\n",
        "    tags = []\n",
        "\n",
        "    current_sentence = []\n",
        "    current_tags = []\n",
        "\n",
        "    with open(filename, encoding='utf8') as f:\n",
        "      # iterate over the lines in the file\n",
        "      for line in f:\n",
        "        if len(line) == 0:\n",
        "          continue\n",
        "        if line == '\\n':\n",
        "          if len(current_sentence) != 0:\n",
        "            sentences.append(current_sentence)\n",
        "            tags.append(current_tags)\n",
        "\n",
        "          current_sentence = []\n",
        "          current_tags = []\n",
        "        else:\n",
        "          if is_labeled:\n",
        "            columns = line.rstrip().split('\\t')\n",
        "            word = columns[0].lower()\n",
        "            tag = columns[1]\n",
        "\n",
        "            current_sentence.append(word)\n",
        "            current_tags.append(tag)\n",
        "          else:\n",
        "            column = line.rstrip().split('\\t')\n",
        "            word = column[0].lower()\n",
        "            current_sentence.append(word)\n",
        "      \n",
        "      if is_labeled:\n",
        "        return sentences, tags\n",
        "      else:\n",
        "        return sentences\n",
        "\n",
        "  def get_batches(self, batch_size, vocab, tagset):\n",
        "    \"\"\"\n",
        "\n",
        "    Batches the data into mini-batches of size `batch_size`\n",
        "\n",
        "    Arguments:\n",
        "    - batch_size:       the desired output batch size\n",
        "    - vocab:            a dictionary mapping word strings to indices\n",
        "    - tagset:           a dictionary mapping tag strings to indices\n",
        "\n",
        "    Outputs:\n",
        "\n",
        "    if is_labeled=True:\n",
        "    - batched_word_indices:     a list of matrices of dimension (batch_size x max_seq_len)\n",
        "    - batched_tag_indices:      a list of matrices of dimension (batch_size x max_seq_len)\n",
        "    - batched_lengths:          a list of arrays of length (batch_size)\n",
        "\n",
        "    if is_labeled=False:\n",
        "    - batched_word_indices:     a list of matrices of dimension (batch_size x max_seq_len)\n",
        "    - batched_lengths:          a list of arrays of length (batch_size)\n",
        "\n",
        "\n",
        "    Description: \n",
        "\n",
        "    This function partitions the data into batches of size batch_size. If the number\n",
        "    of sentences in the document is not an even multiple of batch_size, the final batch\n",
        "    will contain the remaining elements. For example, if there are 82 sentences in the \n",
        "    dataset and batch_size=32, we return a list containing two batches of size 32 \n",
        "    and one final batch of size 18.\n",
        "\n",
        "    batched_word_indices[b] is a (batch_size x max_seq_len) matrix of integers, \n",
        "    containing index representations for sentences in the b-th batch in the document. \n",
        "    The `vocab` dictionary provides the correct mapping from word strings to indices. \n",
        "    If a word is not in the vocabulary, it gets mapped to UNKNOWN_INDEX (1).\n",
        "    `max_seq_len` is the maximum sentence length among the sentences in the current batch, \n",
        "    which will vary between different batches. All sentences shorter than max_seq_len \n",
        "    should be padded on the right with PAD_INDEX (0).\n",
        "\n",
        "    If the document is labeled, we also batch the document's tags. Analogous to \n",
        "    batched_word_indices, batched_tag_indices[b] contains the index representation\n",
        "    for the tags corresponding to the sentences in the b-th batch  in the document. \n",
        "    The `tagset` dictionary provides the correct mapping from tag strings to indicies. \n",
        "    All tag lists shorter than `max_seq_len` are padded with IGNORE_TAG_INDEX (-100).\n",
        "\n",
        "    batched_lengths[b] is a vector of length (batch_size). batched_lengths[b][i] \n",
        "    contains the original sentence length *before* padding for the i-th sentence\n",
        "    in the currrent batch. \n",
        "\n",
        "    \"\"\"\n",
        "    PAD_INDEX = 0             # reserved for padding words\n",
        "    UNKNOWN_INDEX = 1         # reserved for unknown words\n",
        "    IGNORE_TAG_INDEX = -100   # reserved for padding tags\n",
        "\n",
        "    # randomly shuffle the data\n",
        "    np.random.seed(159) # DON'T CHANGE THIS\n",
        "    shuffle = np.random.permutation(range(len(self.sentences)))\n",
        "\n",
        "    sentences = [self.sentences[i] for i in shuffle]\n",
        "    if self.is_labeled:\n",
        "      tags = [self.tags[i] for i in shuffle]\n",
        "    else:\n",
        "      tags = None\n",
        "\n",
        "    batched_word_indices = []\n",
        "    batched_tag_indices = []\n",
        "    batched_lengths = []\n",
        "\n",
        "    #############################\n",
        "    #       YOUR CODE HERE      #\n",
        "    ############################# \n",
        "\n",
        "    # partition into batches of size batch_size \n",
        "    for i in range(0, len(sentences), batch_size):\n",
        "      if (i + batch_size) > len(sentences):\n",
        "        upper_lim = len(sentences)\n",
        "      else: \n",
        "        upper_lim = i + batch_size\n",
        "      batch = sentences[i: upper_lim]\n",
        "      if self.is_labeled:\n",
        "        batch_tags = tags[i: upper_lim]\n",
        "\n",
        "      max_seq_len = max([len(sent) for sent in batch]) \n",
        "\n",
        "      # add default padding values\n",
        "      sent_indices = np.ones((len(batch), max_seq_len)) * PAD_INDEX\n",
        "      tag_indices = np.ones((len(batch), max_seq_len)) * IGNORE_TAG_INDEX\n",
        "      lengths = np.ones((len(batch), ))\n",
        "      for b in range(len(batch)):\n",
        "        sent = batch[b]\n",
        "        if self.is_labeled:\n",
        "          sent_tags = batch_tags[b]\n",
        "        lengths[b] = len(sent)\n",
        "        \n",
        "        # update word and tags\n",
        "        for w in range(len(sent)):\n",
        "          word = sent[w]\n",
        "          if (word in vocab):\n",
        "            sent_indices[b, w] = vocab[word]\n",
        "          else:\n",
        "            sent_indices[b, w] = UNKNOWN_INDEX\n",
        "\n",
        "          if self.is_labeled:\n",
        "            tag = sent_tags[w]\n",
        "            tag_indices[b, w] = tagset[tag]\n",
        "         \n",
        "      batched_word_indices.append(sent_indices)\n",
        "      batched_tag_indices.append(tag_indices)\n",
        "      batched_lengths.append(lengths)    \n",
        "\n",
        "    #############################\n",
        "    #       DO NOT MODIFY       #\n",
        "    #############################\n",
        "    if self.is_labeled:\n",
        "      return batched_word_indices, batched_tag_indices, batched_lengths\n",
        "    else:\n",
        "      return batched_word_indices, batched_lengths"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ePEcb46_zGS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_tagset(tag_file):\n",
        "  \"\"\"\n",
        "  Utility function, loads tag file into a dictionary from tag string to tag index\n",
        "\n",
        "  Arguments:\n",
        "  - tag_file:   file location of the tagset\n",
        "\n",
        "  Outputs:\n",
        "  - tagset:     a dictionary mapping tag strings (e.g. \"VB\") to a unique index\n",
        "  \"\"\"\n",
        "  tagset = {}\n",
        "  with open(tag_file, encoding='utf8') as f:\n",
        "    for line in f:\n",
        "      columns = line.rstrip().split('\\t')\n",
        "      tag = columns[0]\n",
        "      tag_id = int(columns[1])\n",
        "      tagset[tag] = tag_id\n",
        "  \n",
        "  return tagset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mMQIJ_vVuiz",
        "colab_type": "text"
      },
      "source": [
        "The cells below download the data files and construct the corresponding `Dataset` objects. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhXTkpTqGR1H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!wget https://raw.githubusercontent.com/dbamman/nlp20/master/HW_4/pos.train\n",
        "!wget https://raw.githubusercontent.com/dbamman/nlp20/master/HW_4/pos.dev\n",
        "!wget https://raw.githubusercontent.com/dbamman/nlp20/master/HW_4/pos.test\n",
        "!wget https://raw.githubusercontent.com/dbamman/nlp20/master/HW_4/pos.tagset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vtP5seIgBORT",
        "colab": {}
      },
      "source": [
        "# read the files\n",
        "tagset = read_tagset('pos.tagset')\n",
        "train_dataset = Dataset('pos.train', is_labeled=True)\n",
        "dev_dataset = Dataset('pos.dev', is_labeled=True)\n",
        "test_dataset = Dataset('pos.test', is_labeled=False)\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# these should run without errors if implemented correctly\n",
        "train_batch_idx, train_batch_tags, train_batch_lens = train_dataset.get_batches(BATCH_SIZE, vocab, tagset)\n",
        "dev_batch_idx, dev_batch_tags, dev_batch_lens = dev_dataset.get_batches(BATCH_SIZE, vocab, tagset)\n",
        "test_batch_idx, test_batch_lens = test_dataset.get_batches(BATCH_SIZE, vocab, tagset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-nnX7WxqDJ3",
        "colab_type": "text"
      },
      "source": [
        "### Part 2: Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMtkCBt_wzIS",
        "colab_type": "text"
      },
      "source": [
        "Next, we will implement utility functions that will later be used to assess our model's perfomance. \n",
        "\n",
        "**Please make sure that**\n",
        "\n",
        "*   Your implementation is self-contained. That is, keep all helper functions or variables inside of your function.\n",
        "*   Your implementation does not import any additional libraries. You will not receive credit if you do."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQLiM0ukG-4W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The accuracy function has been implemented for you\n",
        "\n",
        "def accuracy(true, pred):\n",
        "  \"\"\"\n",
        "  Arguments:\n",
        "  - true:       a list of true label values (integers)\n",
        "  - pred:       a list of predicted label values (integers)\n",
        "\n",
        "  Output:\n",
        "  - accuracy:   the prediction accuracy\n",
        "  \"\"\"\n",
        "  true = np.array(true)\n",
        "  pred = np.array(pred)\n",
        "\n",
        "  num_correct = sum(true == pred)\n",
        "  num_total = len(true)\n",
        "  return num_correct / num_total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChJjUu45qFM8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def confusion_matrix(true, pred, num_tags):\n",
        "  \"\"\"\n",
        "  Arguments:\n",
        "  - true:       a list of true label values (integers)\n",
        "  - pred:       a list of predicted label values (integers)\n",
        "  - num_tags:   the number of possible tags\n",
        "                true and pred will both contain integers between\n",
        "                0 and num_tags - 1 (inclusive)\n",
        "\n",
        "  Output: \n",
        "  - confusion_matrix:   a (num_tags x num_tags) matrix of integers\n",
        "\n",
        "  confusion_matrix[i][j] = # predictions where true label\n",
        "  was i and predicted label was j\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  confusion_matrix = np.zeros((num_tags, num_tags))\n",
        "\n",
        "  #############################\n",
        "  #       YOUR CODE HERE      #\n",
        "  #############################\n",
        "  # for i in true:\n",
        "  #   for j in pred:\n",
        "  #     confusion_matrix[i][j] += 1\n",
        "\n",
        "  for i, j in zip(true, pred):\n",
        "    confusion_matrix[i][j] += 1\n",
        "      \n",
        "  return confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Hdj6QSaBV9S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def precision(true, pred, num_tags):\n",
        "  \"\"\"\n",
        "  Arguments:\n",
        "  - true:       a list of true label values (integers)\n",
        "  - pred:       a list of predicted label values (integers)\n",
        "  - num_tags:   the number of possible tags\n",
        "                true and pred will both contain integers between\n",
        "                0 and num_tags - 1 (inclusive)\n",
        "\n",
        "  Output: \n",
        "  - precision:  an array of length num_tags, where precision[i]\n",
        "                gives the precision of class i\n",
        "\n",
        "  Hints:  the confusion matrix may be useful\n",
        "          be careful about zero division\n",
        "  \"\"\"\n",
        "\n",
        "  precision = np.zeros(num_tags)\n",
        "\n",
        "  #############################\n",
        "  #       YOUR CODE HERE      #\n",
        "  #############################\n",
        "\n",
        "  matrix = confusion_matrix(true, pred, num_tags)\n",
        "\n",
        "  for i in range(num_tags): # loop over all tag values\n",
        "    tp = matrix[i][i]\n",
        "    fp = sum([matrix[j][i] for j in range(num_tags) if j != i])\n",
        "    if tp + fp == 0: #account for zero division error\n",
        "      precision[i] = 0  \n",
        "    else: \n",
        "      precision[i] = tp / (tp + fp)\n",
        "  \n",
        "  return precision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJL55TnOBVxl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def recall(true, pred, num_tags):\n",
        "  \"\"\"\n",
        "  Arguments:\n",
        "  - true:       a list of true label values (integers)\n",
        "  - pred:       a list of predicted label values (integers)\n",
        "  - num_tags:   the number of possible tags\n",
        "                true and pred will both contain integers between\n",
        "                0 and num_tags - 1 (inclusive)\n",
        "\n",
        "  Output: \n",
        "  - recall:     an array of length num_tags, where recall[i]\n",
        "                gives the recall of class i\n",
        "\n",
        "  Hints:  the confusion matrix may be useful\n",
        "          be careful about zero division\n",
        "  \"\"\"\n",
        "\n",
        "  \"\"\"\n",
        "  YOUR CODE HERE\n",
        "  \"\"\"\n",
        "  recall = np.zeros(num_tags)\n",
        "\n",
        "  #############################\n",
        "  #       YOUR CODE HERE      #\n",
        "  #############################\n",
        "\n",
        "  matrix = confusion_matrix(true, pred, num_tags)\n",
        "\n",
        "  for i in range(num_tags): # loop over all tag values\n",
        "    tp = matrix[i][i]\n",
        "    fn = sum([matrix[i][j] for j in range(num_tags) if j != i])\n",
        "    if tp + fn == 0: #account for zero division error\n",
        "      recall[i] = 0  \n",
        "    else: \n",
        "      recall[i] = tp / (tp + fn)\n",
        "\n",
        "  return recall"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7drr7z1VBVjD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def f1_score(true, pred, num_tags):\n",
        "  \"\"\"\n",
        "  Arguments:\n",
        "  - true:       a list of true label values (integers)\n",
        "  - pred:       a list of predicted label values (integers)\n",
        "  - num_tags:   the number of possible tags\n",
        "                true and pred will both contain integers between\n",
        "                0 and num_tags - 1 (inclusive)\n",
        "\n",
        "  Output: \n",
        "  - f1:         an array of length num_tags, where f1[i]\n",
        "                gives the recall of class i\n",
        "  \"\"\"\n",
        "  f1 = np.zeros(num_tags)\n",
        "\n",
        "  #############################\n",
        "  #       YOUR CODE HERE      #\n",
        "  #############################\n",
        "\n",
        "  rec_arr = recall(true, pred, num_tags)\n",
        "  pre_arr = precision(true, pred, num_tags)\n",
        "  for i in range(num_tags): # loop over all tag values\n",
        "    if (pre_arr[i] + rec_arr[i]) == 0:\n",
        "      f1[i] = 0\n",
        "    else:\n",
        "      f1[i] = (2 * pre_arr[i] * rec_arr[i]) / (pre_arr[i] + rec_arr[i])\n",
        "\n",
        "  return f1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GS1p55P5UGv4",
        "colab_type": "text"
      },
      "source": [
        "### Part 3: Building the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IPoFwqfoFOO",
        "colab_type": "text"
      },
      "source": [
        "Fill in the blanks in `LSTMTagger`'s `__init__` function. If you get stuck, you can reference PyTorch's [torch.nn documentation](https://pytorch.org/docs/stable/nn.html) or [this official tutorial](https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html) on LSTM sequence labeling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6J3z3T0USI8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTMTagger(nn.Module):\n",
        "  \"\"\"\n",
        "  An LSTM model for sequence labeling\n",
        "\n",
        "  Initialization Arguments:\n",
        "  - embeddings:   a matrix of size (vocab_size, emb_dim)\n",
        "                  containing pretrained embedding weights\n",
        "  - hidden_dim:   the LSTM's hidden layer size\n",
        "  - tagset_size:  the number of possible output tags\n",
        "\n",
        "  \"\"\"\n",
        "  def __init__(self, embeddings, hidden_dim, tagset_size):\n",
        "    super().__init__()\n",
        "  \n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.num_labels = tagset_size\n",
        "\n",
        "    #############################\n",
        "    #       YOUR CODE HERE      #\n",
        "    #############################\n",
        "\n",
        "    # Initialize a PyTorch embeddings layer using the pretrained embedding weights\n",
        "    # print(embeddings.shape[0])\n",
        "    self.embeddings = nn.Embedding(embeddings.shape[0], embeddings.shape[1])\n",
        "    self.embeddings.weight.data.copy_(embeddings)\n",
        "    # self.embeddings = nn.Embedding(embeddings.size(0), embeddings.size(1))\n",
        "    # self.embeddings = nn.Embedding.from_pretrained(embeddings, freeze=False)\n",
        "\n",
        "    # Initialize an LSTM layer\n",
        "    self.lstm = nn.LSTM(embeddings.shape[1], hidden_dim)\n",
        "    # self.lstm = nn.LSTM(embeddings.size(1), hidden_dim)\n",
        "\n",
        "    # Initialize a single feedforward layer\n",
        "    self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
        "  \n",
        "  def forward(self, indices, lengths):\n",
        "    \"\"\"\n",
        "    Runs a batched sequence through the model and returns output logits\n",
        "\n",
        "    Arguments:\n",
        "    - indices:  a matrix of size (batch_size x max_seq_len)\n",
        "                containing the word indices of sentences in the batch\n",
        "    - lengths:  a vector of size (batch_size) containing the\n",
        "                original lengths of the sequences before padding\n",
        "\n",
        "    Output:\n",
        "    - logits:   a matrix of size (batch_size x max_seq_len x num_tags)\n",
        "                gives a score to each possible tag for each word\n",
        "                in each sentence \n",
        "    \"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # cast arrays as PyTorch data types and move to GPU memory\n",
        "    indices = torch.LongTensor(indices).to(device)\n",
        "    lengths = torch.LongTensor(lengths).to(device)\n",
        "    \n",
        "    # convert word indices to word embeddings\n",
        "    embeddings = self.embeddings(indices)\n",
        "\n",
        "    # pack/pad handles variable length sequence batching\n",
        "    # see here if you're curious: https://gist.github.com/HarshTrivedi/f4e7293e941b17d19058f6fb90ab0fec\n",
        "    packed_input_embs = pack_padded_sequence(embeddings, lengths, batch_first=True, enforce_sorted=False)\n",
        "    # run input through LSTM layer\n",
        "    packed_output, _ = self.lstm(packed_input_embs)\n",
        "    # unpack sequences into original format\n",
        "    padded_output, output_lengths = pad_packed_sequence(packed_output, batch_first=True)\n",
        "\n",
        "    logits = self.hidden2tag(padded_output)\n",
        "    return logits\n",
        "\n",
        "  def run_training(self, train_dataset, dev_dataset, batch_size, vocab, tagset,\n",
        "                         lr=5e-4, num_epochs=100, eval_every=5):\n",
        "    \"\"\"\n",
        "    Trains the model on the training data with a learning rate of lr\n",
        "    for num_epochs. Evaluates the model on the dev data eval_every epochs.\n",
        "\n",
        "    Arguments:\n",
        "    - train_dataset:  Dataset object containing the training data\n",
        "    - dev_dataset:    Dataset object containing the dev data\n",
        "    - batch_size:     batch size for train/dev data\n",
        "    - vocab:          a dictionary mapping word strings to indices\n",
        "    - tagset:         a dictionary mapping tag strings to indices\n",
        "    - lr:             learning rate\n",
        "    - num_epochs:     number of epochs to train for\n",
        "    - eval_every:     evaluation is run eval_every epochs\n",
        "    \"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    if str(device) == 'cpu':\n",
        "      print(\"Training only supported in GPU environment\")\n",
        "      return\n",
        "\n",
        "    # clear unreferenced data/models from GPU memory \n",
        "    torch.cuda.empty_cache()\n",
        "    # move model to GPU memory\n",
        "    self.to(device)\n",
        "\n",
        "    # set the optimizer (Adam) and loss function (CrossEnt)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    loss_function = nn.CrossEntropyLoss(ignore_index=-100)\n",
        "\n",
        "    # batch training and dev data\n",
        "    train_batch_idx, train_batch_tags, train_batch_lens = train_dataset.get_batches(BATCH_SIZE, vocab, tagset)\n",
        "    dev_batch_idx, dev_batch_tags, dev_batch_lens = dev_dataset.get_batches(BATCH_SIZE, vocab, tagset)\n",
        "\n",
        "    print(\"**** TRAINING *****\")\n",
        "    for i in range(num_epochs):\n",
        "      # sets the model in train mode\n",
        "      self.train()\n",
        "\n",
        "      total_loss = 0\n",
        "      for b in range(len(train_batch_idx)):\n",
        "        # compute the logits\n",
        "        logits = model.forward(train_batch_idx[b], train_batch_lens[b])\n",
        "        # move labels to GPU memory\n",
        "        labels = torch.LongTensor(train_batch_tags[b]).to(device)\n",
        "        # compute the loss with respect to true labels\n",
        "        loss = loss_function(logits.view(-1, len(tagset)), labels.view(-1))\n",
        "        total_loss += loss\n",
        "        # propagate gradients backward\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # set model gradients to zero before performing next forward pass\n",
        "        self.zero_grad()\n",
        "\n",
        "      print(\"Epoch {} | Loss: {}\".format(i, total_loss))\n",
        "\n",
        "      if (i + 1) % eval_every == 0:\n",
        "        print(\"**** EVALUATION *****\")\n",
        "        # sets the model in evaluate mode (no gradients)\n",
        "        self.eval()\n",
        "        # compute dev f1 score\n",
        "        acc, true, pred = self.evaluate(dev_batch_idx, dev_batch_lens, dev_batch_tags, tagset)\n",
        "        print(\"Dev Accuracy: {}\".format(acc))\n",
        "        print(\"**********************\")\n",
        "\n",
        "  def evaluate(self, batched_sentences, batched_lengths, batched_labels, tagset):\n",
        "    \"\"\"\n",
        "    Evaluate the model's predictions on the provided dataset. \n",
        "\n",
        "    Arguments:\n",
        "    - batched_sentences:  a list of matrices, each of size (batch_size x max_seq_len),\n",
        "                          containing the word indices of sentences in the batch\n",
        "    - batched_lengths:    a list of vectors, each of size (batch_size), containing the\n",
        "                          original lengths of the sequences before padding\n",
        "    - batched_labels:     a list of matrices, each of size (batch_size x max_seq_len),\n",
        "                          containing the tag indices corresponding to sentences in the batch\n",
        "    - num_tags:           the number of possible output tags\n",
        "\n",
        "    Output:\n",
        "    - accuracy:           the model's prediction accuracy\n",
        "    - all_true_labels:    a flattened list of all true labels\n",
        "    - all_predictions:    a flattened list of all of the model's corresponding predictions\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    all_true_labels = []\n",
        "    all_predictions = []\n",
        "\n",
        "    for b in range(len(batched_sentences)):\n",
        "      logits = self.forward(batched_sentences[b], batched_lengths[b])\n",
        "      batch_predictions = torch.argmax(logits, dim=-1).cpu().numpy()\n",
        "\n",
        "      batch_size, _ = batched_sentences[b].shape\n",
        "\n",
        "      for i in range(batch_size):\n",
        "        tags = batched_labels[b][i]\n",
        "        preds = batch_predictions[i]\n",
        "        \n",
        "        seq_len = int(batched_lengths[b][i])\n",
        "        for j in range(seq_len):\n",
        "          all_predictions.append(int(preds[j]))\n",
        "          all_true_labels.append(int(tags[j]))\n",
        "      \n",
        "    \n",
        "    acc = accuracy(all_true_labels, all_predictions)\n",
        "      \n",
        "    return acc, all_true_labels, all_predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4AOB94R9RFo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def set_seed(seed):\n",
        "  \"\"\"\n",
        "  Sets random seeds and sets model in deterministic\n",
        "  training mode. Ensures reproducible results\n",
        "  \"\"\"\n",
        "  torch.manual_seed(seed)\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "  np.random.seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AuNeDk9qAM_",
        "colab_type": "text"
      },
      "source": [
        "## Training the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WTEvLeVuNWl",
        "colab_type": "text"
      },
      "source": [
        "Run the cells below to train your model. If all of the previous sections are implemented correctly, you should see\n",
        "\n",
        "\n",
        "*   the loss decreasing consistently for every epoch\n",
        "*   the dev accuracy increasing until convergence around ~0.88\n",
        "\n",
        "The staff solution achieves an accuracy of 0.880 after 25 epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9NqwYnfU2WB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 745
        },
        "outputId": "c5a6fca1-9469-48b5-a69c-ecb96f55d4c3"
      },
      "source": [
        "# sets the random seed – DO NOT change this\n",
        "# this ensures deterministic results that are comparable with the staff values\n",
        "set_seed(159)\n",
        "\n",
        "HIDDEN_SIZE = 64\n",
        "# intialize a new LSTMTagger model\n",
        "model = LSTMTagger(embeddings, HIDDEN_SIZE, len(tagset))\n",
        "# train the model\n",
        "model.run_training(train_dataset, dev_dataset, BATCH_SIZE, vocab, tagset,   \n",
        "                   lr=5e-4, num_epochs=25, eval_every=5)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "**** TRAINING *****\n",
            "Epoch 0 | Loss: 966.6653442382812\n",
            "Epoch 1 | Loss: 417.92913818359375\n",
            "Epoch 2 | Loss: 267.7360534667969\n",
            "Epoch 3 | Loss: 209.37423706054688\n",
            "Epoch 4 | Loss: 179.8599395751953\n",
            "**** EVALUATION *****\n",
            "Dev Accuracy: 0.8589779280174985\n",
            "**********************\n",
            "Epoch 5 | Loss: 161.93316650390625\n",
            "Epoch 6 | Loss: 149.59909057617188\n",
            "Epoch 7 | Loss: 140.41824340820312\n",
            "Epoch 8 | Loss: 133.19635009765625\n",
            "Epoch 9 | Loss: 127.2813491821289\n",
            "**** EVALUATION *****\n",
            "Dev Accuracy: 0.8754424338834759\n",
            "**********************\n",
            "Epoch 10 | Loss: 122.29289245605469\n",
            "Epoch 11 | Loss: 117.97274780273438\n",
            "Epoch 12 | Loss: 114.15171813964844\n",
            "Epoch 13 | Loss: 110.71771240234375\n",
            "Epoch 14 | Loss: 107.54832458496094\n",
            "**** EVALUATION *****\n",
            "Dev Accuracy: 0.8791409823026447\n",
            "**********************\n",
            "Epoch 15 | Loss: 104.69400787353516\n",
            "Epoch 16 | Loss: 102.0001449584961\n",
            "Epoch 17 | Loss: 99.43143463134766\n",
            "Epoch 18 | Loss: 97.04694366455078\n",
            "Epoch 19 | Loss: 94.7793960571289\n",
            "**** EVALUATION *****\n",
            "Dev Accuracy: 0.8795784450188905\n",
            "**********************\n",
            "Epoch 20 | Loss: 92.61573028564453\n",
            "Epoch 21 | Loss: 90.54859924316406\n",
            "Epoch 22 | Loss: 88.55851745605469\n",
            "Epoch 23 | Loss: 86.857421875\n",
            "Epoch 24 | Loss: 84.86511993408203\n",
            "**** EVALUATION *****\n",
            "Dev Accuracy: 0.8791807516404851\n",
            "**********************\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JH5giKgvJp0c",
        "colab_type": "text"
      },
      "source": [
        "Once the model is trained, run the cells below to print the precision, recall, and $F_1$ score per class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLqaZ_6cMMPM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eval_per_class(model, dataset, vocab, tagset):\n",
        "  \"\"\"\n",
        "  Prints precision, recall, and F1 for each class in the tagset\n",
        "  \"\"\"\n",
        "  # batch the data\n",
        "  batched_idx, batched_tags, batched_lens = dev_dataset.get_batches(BATCH_SIZE, vocab, tagset)\n",
        "  # compute idx --> tag from tag --> idx\n",
        "  reverse_tagset = {v: k for k,v in tagset.items()}\n",
        "  # evaluate model on hold-out set\n",
        "  acc, true, pred = model.evaluate(batched_idx, batched_lens, batched_tags, tagset)\n",
        "  true = np.array(true)\n",
        "  pred = np.array(pred)\n",
        "\n",
        "  pr = precision(true, pred, len(tagset))\n",
        "  re = recall(true, pred, len(tagset))\n",
        "  f1 = f1_score(true, pred, len(tagset))\n",
        "\n",
        "  for idx, tag in reverse_tagset.items():\n",
        "    print(\"***********************\")\n",
        "    print(\"TAG: {}\".format(tag))\n",
        "    num_pred = np.sum(pred == idx)\n",
        "    num_true = np.sum(true == idx)\n",
        "    print(\"({} pred, {} true)\".format(num_pred, num_true))\n",
        "\n",
        "    print(\"PRECISION: \\t{:.3f}\".format(pr[idx]))\n",
        "    print(\"RECALL: \\t{:.3f}\".format(re[idx]))\n",
        "    print(\"F1 SCORE: \\t{:.3f}\".format(f1[idx]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tTEpCBsuYuP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "06422320-6748-4f41-cb0e-d6548b27251d"
      },
      "source": [
        "eval_per_class(model, dev_dataset, vocab, tagset)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***********************\n",
            "TAG: $\n",
            "(13 pred, 14 true)\n",
            "PRECISION: \t1.000\n",
            "RECALL: \t0.929\n",
            "F1 SCORE: \t0.963\n",
            "***********************\n",
            "TAG: ''\n",
            "(96 pred, 88 true)\n",
            "PRECISION: \t0.854\n",
            "RECALL: \t0.932\n",
            "F1 SCORE: \t0.891\n",
            "***********************\n",
            "TAG: ,\n",
            "(967 pred, 936 true)\n",
            "PRECISION: \t0.939\n",
            "RECALL: \t0.970\n",
            "F1 SCORE: \t0.954\n",
            "***********************\n",
            "TAG: -LRB-\n",
            "(107 pred, 117 true)\n",
            "PRECISION: \t0.953\n",
            "RECALL: \t0.872\n",
            "F1 SCORE: \t0.911\n",
            "***********************\n",
            "TAG: -RRB-\n",
            "(123 pred, 120 true)\n",
            "PRECISION: \t0.919\n",
            "RECALL: \t0.942\n",
            "F1 SCORE: \t0.930\n",
            "***********************\n",
            "TAG: .\n",
            "(1461 pred, 1503 true)\n",
            "PRECISION: \t0.988\n",
            "RECALL: \t0.961\n",
            "F1 SCORE: \t0.974\n",
            "***********************\n",
            "TAG: :\n",
            "(98 pred, 106 true)\n",
            "PRECISION: \t0.980\n",
            "RECALL: \t0.906\n",
            "F1 SCORE: \t0.941\n",
            "***********************\n",
            "TAG: ADD\n",
            "(12 pred, 81 true)\n",
            "PRECISION: \t0.167\n",
            "RECALL: \t0.025\n",
            "F1 SCORE: \t0.043\n",
            "***********************\n",
            "TAG: AFX\n",
            "(0 pred, 4 true)\n",
            "PRECISION: \t0.000\n",
            "RECALL: \t0.000\n",
            "F1 SCORE: \t0.000\n",
            "***********************\n",
            "TAG: CC\n",
            "(781 pred, 781 true)\n",
            "PRECISION: \t0.988\n",
            "RECALL: \t0.988\n",
            "F1 SCORE: \t0.988\n",
            "***********************\n",
            "TAG: CD\n",
            "(329 pred, 378 true)\n",
            "PRECISION: \t0.845\n",
            "RECALL: \t0.735\n",
            "F1 SCORE: \t0.786\n",
            "***********************\n",
            "TAG: DT\n",
            "(1970 pred, 1943 true)\n",
            "PRECISION: \t0.968\n",
            "RECALL: \t0.981\n",
            "F1 SCORE: \t0.975\n",
            "***********************\n",
            "TAG: EX\n",
            "(49 pred, 56 true)\n",
            "PRECISION: \t0.939\n",
            "RECALL: \t0.821\n",
            "F1 SCORE: \t0.876\n",
            "***********************\n",
            "TAG: FW\n",
            "(2 pred, 30 true)\n",
            "PRECISION: \t0.500\n",
            "RECALL: \t0.033\n",
            "F1 SCORE: \t0.062\n",
            "***********************\n",
            "TAG: GW\n",
            "(21 pred, 32 true)\n",
            "PRECISION: \t0.000\n",
            "RECALL: \t0.000\n",
            "F1 SCORE: \t0.000\n",
            "***********************\n",
            "TAG: HYPH\n",
            "(77 pred, 95 true)\n",
            "PRECISION: \t0.844\n",
            "RECALL: \t0.684\n",
            "F1 SCORE: \t0.756\n",
            "***********************\n",
            "TAG: IN\n",
            "(2443 pred, 2353 true)\n",
            "PRECISION: \t0.909\n",
            "RECALL: \t0.944\n",
            "F1 SCORE: \t0.926\n",
            "***********************\n",
            "TAG: JJ\n",
            "(1677 pred, 1655 true)\n",
            "PRECISION: \t0.830\n",
            "RECALL: \t0.841\n",
            "F1 SCORE: \t0.836\n",
            "***********************\n",
            "TAG: JJR\n",
            "(39 pred, 47 true)\n",
            "PRECISION: \t0.615\n",
            "RECALL: \t0.511\n",
            "F1 SCORE: \t0.558\n",
            "***********************\n",
            "TAG: JJS\n",
            "(71 pred, 84 true)\n",
            "PRECISION: \t0.859\n",
            "RECALL: \t0.726\n",
            "F1 SCORE: \t0.787\n",
            "***********************\n",
            "TAG: LS\n",
            "(8 pred, 5 true)\n",
            "PRECISION: \t0.375\n",
            "RECALL: \t0.600\n",
            "F1 SCORE: \t0.462\n",
            "***********************\n",
            "TAG: MD\n",
            "(354 pred, 358 true)\n",
            "PRECISION: \t0.980\n",
            "RECALL: \t0.969\n",
            "F1 SCORE: \t0.975\n",
            "***********************\n",
            "TAG: NFP\n",
            "(31 pred, 60 true)\n",
            "PRECISION: \t0.774\n",
            "RECALL: \t0.400\n",
            "F1 SCORE: \t0.527\n",
            "***********************\n",
            "TAG: NN\n",
            "(3521 pred, 3336 true)\n",
            "PRECISION: \t0.817\n",
            "RECALL: \t0.862\n",
            "F1 SCORE: \t0.839\n",
            "***********************\n",
            "TAG: NNP\n",
            "(2058 pred, 1816 true)\n",
            "PRECISION: \t0.656\n",
            "RECALL: \t0.744\n",
            "F1 SCORE: \t0.697\n",
            "***********************\n",
            "TAG: NNPS\n",
            "(24 pred, 63 true)\n",
            "PRECISION: \t0.792\n",
            "RECALL: \t0.302\n",
            "F1 SCORE: \t0.437\n",
            "***********************\n",
            "TAG: NNS\n",
            "(936 pred, 929 true)\n",
            "PRECISION: \t0.807\n",
            "RECALL: \t0.813\n",
            "F1 SCORE: \t0.810\n",
            "***********************\n",
            "TAG: PDT\n",
            "(5 pred, 21 true)\n",
            "PRECISION: \t0.400\n",
            "RECALL: \t0.095\n",
            "F1 SCORE: \t0.154\n",
            "***********************\n",
            "TAG: POS\n",
            "(87 pred, 84 true)\n",
            "PRECISION: \t0.943\n",
            "RECALL: \t0.976\n",
            "F1 SCORE: \t0.959\n",
            "***********************\n",
            "TAG: PRP\n",
            "(1494 pred, 1487 true)\n",
            "PRECISION: \t0.988\n",
            "RECALL: \t0.993\n",
            "F1 SCORE: \t0.990\n",
            "***********************\n",
            "TAG: PRP$\n",
            "(308 pred, 315 true)\n",
            "PRECISION: \t0.990\n",
            "RECALL: \t0.968\n",
            "F1 SCORE: \t0.979\n",
            "***********************\n",
            "TAG: RB\n",
            "(1175 pred, 1292 true)\n",
            "PRECISION: \t0.903\n",
            "RECALL: \t0.821\n",
            "F1 SCORE: \t0.860\n",
            "***********************\n",
            "TAG: RBR\n",
            "(34 pred, 22 true)\n",
            "PRECISION: \t0.353\n",
            "RECALL: \t0.545\n",
            "F1 SCORE: \t0.429\n",
            "***********************\n",
            "TAG: RBS\n",
            "(22 pred, 20 true)\n",
            "PRECISION: \t0.591\n",
            "RECALL: \t0.650\n",
            "F1 SCORE: \t0.619\n",
            "***********************\n",
            "TAG: RP\n",
            "(61 pred, 75 true)\n",
            "PRECISION: \t0.689\n",
            "RECALL: \t0.560\n",
            "F1 SCORE: \t0.618\n",
            "***********************\n",
            "TAG: SYM\n",
            "(7 pred, 20 true)\n",
            "PRECISION: \t0.429\n",
            "RECALL: \t0.150\n",
            "F1 SCORE: \t0.222\n",
            "***********************\n",
            "TAG: TO\n",
            "(349 pred, 359 true)\n",
            "PRECISION: \t0.854\n",
            "RECALL: \t0.830\n",
            "F1 SCORE: \t0.842\n",
            "***********************\n",
            "TAG: UH\n",
            "(63 pred, 116 true)\n",
            "PRECISION: \t0.889\n",
            "RECALL: \t0.483\n",
            "F1 SCORE: \t0.626\n",
            "***********************\n",
            "TAG: VB\n",
            "(1076 pred, 1122 true)\n",
            "PRECISION: \t0.932\n",
            "RECALL: \t0.894\n",
            "F1 SCORE: \t0.913\n",
            "***********************\n",
            "TAG: VBD\n",
            "(517 pred, 520 true)\n",
            "PRECISION: \t0.872\n",
            "RECALL: \t0.867\n",
            "F1 SCORE: \t0.870\n",
            "***********************\n",
            "TAG: VBG\n",
            "(347 pred, 384 true)\n",
            "PRECISION: \t0.853\n",
            "RECALL: \t0.771\n",
            "F1 SCORE: \t0.810\n",
            "***********************\n",
            "TAG: VBN\n",
            "(496 pred, 476 true)\n",
            "PRECISION: \t0.808\n",
            "RECALL: \t0.842\n",
            "F1 SCORE: \t0.825\n",
            "***********************\n",
            "TAG: VBP\n",
            "(776 pred, 771 true)\n",
            "PRECISION: \t0.916\n",
            "RECALL: \t0.922\n",
            "F1 SCORE: \t0.919\n",
            "***********************\n",
            "TAG: VBZ\n",
            "(643 pred, 643 true)\n",
            "PRECISION: \t0.960\n",
            "RECALL: \t0.960\n",
            "F1 SCORE: \t0.960\n",
            "***********************\n",
            "TAG: WDT\n",
            "(99 pred, 106 true)\n",
            "PRECISION: \t0.788\n",
            "RECALL: \t0.736\n",
            "F1 SCORE: \t0.761\n",
            "***********************\n",
            "TAG: WP\n",
            "(118 pred, 113 true)\n",
            "PRECISION: \t0.898\n",
            "RECALL: \t0.938\n",
            "F1 SCORE: \t0.918\n",
            "***********************\n",
            "TAG: WP$\n",
            "(0 pred, 2 true)\n",
            "PRECISION: \t0.000\n",
            "RECALL: \t0.000\n",
            "F1 SCORE: \t0.000\n",
            "***********************\n",
            "TAG: WRB\n",
            "(112 pred, 113 true)\n",
            "PRECISION: \t1.000\n",
            "RECALL: \t0.991\n",
            "F1 SCORE: \t0.996\n",
            "***********************\n",
            "TAG: XX\n",
            "(0 pred, 3 true)\n",
            "PRECISION: \t0.000\n",
            "RECALL: \t0.000\n",
            "F1 SCORE: \t0.000\n",
            "***********************\n",
            "TAG: ``\n",
            "(88 pred, 91 true)\n",
            "PRECISION: \t0.920\n",
            "RECALL: \t0.890\n",
            "F1 SCORE: \t0.905\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lefzFwCD8AJU",
        "colab_type": "text"
      },
      "source": [
        "## Part 4: Model Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxZ_Wn75uw7n",
        "colab_type": "text"
      },
      "source": [
        "Congratulations, you've just trained a neural network!\n",
        "\n",
        "Now, improve the `LSTMTagger` model and implementing the `init` function in the `FancyTagger` class below. \n",
        "* Feel free to replace the `forward` function inherited from `LSTMTagger` if \n",
        "you need to, but it should not be necessary to receive full credit. Credit will be awarded based on the performance on a holdout test set. \n",
        "* Do not modify any of the cells above when completing part 4. Instead, insert cells below if you need to perform any additional computations. \n",
        "* You are allowed to use any function in `torch.nn`. You are **not** allowed to import any libraries or use implementations copied from the internet. \n",
        "\n",
        "Before submitting, please describe your modifications below:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ya-aaGh6l8D",
        "colab_type": "text"
      },
      "source": [
        "I decided to increase the size of the data by increasing the dimensionality of word-embeddings and the number of common words selected. \n",
        "Instead of loading the 10,000 most common word 50-dimensional embeddings, I load the 500,000 most common word 300-dimensional embeddings.\n",
        "\n",
        "I also choose to use a bi-directional LSTM and dropout layer (p=0.6) for every layer except the output layer. \n",
        "\n",
        "All these modifications increased the accuracy of my model from ~0.88 to ~0.928.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lF82056f6WXO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # # this loads the 10,000 most common word 50-dimensional embeddings\n",
        "# vocab_size = 10000\n",
        "# embeddings, vocab = read_embeddings('glove.6B.50d.txt', vocab_size)\n",
        "\n",
        "# this loads the 500,000 most common word 300-dimensional embeddings\n",
        "vocab_size = 500000\n",
        "embeddings, vocab = read_embeddings('glove.6B.300d.txt', vocab_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKz2PLbu5d8Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FancyTagger(LSTMTagger):\n",
        "  \"\"\"\n",
        "  An improved neural model for sequence labeling\n",
        "\n",
        "  Starter code from LSTMTagger has already been provided, but\n",
        "  feel free to change the init and forward function internals\n",
        "  if your model design requires it (though this is not necessary\n",
        "  to receive full credit).\n",
        "\n",
        "  You may use any component in torch.nn. You may NOT\n",
        "  import any additional libraries/modules. \n",
        "\n",
        "  \"\"\"\n",
        "  def __init__(self, embeddings, hidden_dim, tagset_size):\n",
        "    # initializes the parent LSTMTagger class\n",
        "    # inherits forward, evaluate, and run_training methods\n",
        "    super().__init__(embeddings, hidden_dim, tagset_size)\n",
        "  \n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.num_labels = tagset_size\n",
        "\n",
        "    #############################\n",
        "    #       YOUR CODE HERE      #\n",
        "    #############################\n",
        "  # #Idea: Make the model bidirectional and add dropout\n",
        "  # #use bigger data and vocab size\n",
        "  #   self.embeddings = \n",
        "\n",
        "  #   self.lstm = nn.LSTM()\n",
        "\n",
        "  # --------------------------------------------------------------------------------------\n",
        "\n",
        "    # Initialize a PyTorch embeddings layer using the pretrained embedding weights\n",
        "    # print(embeddings.shape[0])\n",
        "    self.embeddings = nn.Embedding(embeddings.shape[0], embeddings.shape[1])\n",
        "    self.embeddings.weight.data.copy_(embeddings)\n",
        "    # self.embeddings = nn.Embedding(embeddings.size(0), embeddings.size(1))\n",
        "\n",
        "    # Initialize an LSTM layer\n",
        "    self.lstm = nn.LSTM(embeddings.shape[1], hidden_dim, num_layers=2, bidirectional=True, dropout=0.6)\n",
        "    # self.lstm = nn.LSTM(embeddings.size(1), hidden_dim)\n",
        "\n",
        "    # Initialize a single feedforward layer\n",
        "    self.hidden2tag = nn.Linear(hidden_dim*2, tagset_size)\n",
        "\n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGDY4ymJvo3h",
        "colab_type": "text"
      },
      "source": [
        "Run the training script below to train the `FancyTagger` model. Again, feel free to adjust any hyperparameters if necessary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lnp-tWl9Vbo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        },
        "outputId": "633e8b14-6e78-4b81-f225-8177b3e90d9d"
      },
      "source": [
        "model = FancyTagger(embeddings, HIDDEN_SIZE, len(tagset))\n",
        "print(model)\n",
        "model.run_training(train_dataset, dev_dataset, BATCH_SIZE, vocab, tagset,   \n",
        "                   lr=5e-4, num_epochs=15, eval_every=5)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FancyTagger(\n",
            "  (embeddings): Embedding(500000, 300)\n",
            "  (lstm): LSTM(300, 64, num_layers=2, dropout=0.6, bidirectional=True)\n",
            "  (hidden2tag): Linear(in_features=128, out_features=50, bias=True)\n",
            ")\n",
            "**** TRAINING *****\n",
            "Epoch 0 | Loss: 772.9916381835938\n",
            "Epoch 1 | Loss: 222.7566680908203\n",
            "Epoch 2 | Loss: 129.33763122558594\n",
            "Epoch 3 | Loss: 97.31932067871094\n",
            "Epoch 4 | Loss: 79.34996795654297\n",
            "**** EVALUATION *****\n",
            "Dev Accuracy: 0.920381785643269\n",
            "**********************\n",
            "Epoch 5 | Loss: 67.7364273071289\n",
            "Epoch 6 | Loss: 59.1616325378418\n",
            "Epoch 7 | Loss: 52.34418869018555\n",
            "Epoch 8 | Loss: 47.127315521240234\n",
            "Epoch 9 | Loss: 42.47673034667969\n",
            "**** EVALUATION *****\n",
            "Dev Accuracy: 0.9270232650626367\n",
            "**********************\n",
            "Epoch 10 | Loss: 38.620243072509766\n",
            "Epoch 11 | Loss: 35.0311279296875\n",
            "Epoch 12 | Loss: 32.10194778442383\n",
            "Epoch 13 | Loss: 29.4144287109375\n",
            "Epoch 14 | Loss: 26.3944091796875\n",
            "**** EVALUATION *****\n",
            "Dev Accuracy: 0.9283754225492146\n",
            "**********************\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgLM__WZw4wz",
        "colab_type": "text"
      },
      "source": [
        "### Save Predictions\n",
        "\n",
        "When you are satisfied with your `FancyTagger`'s performance on the dev set, run the cell below to write your predictions on the test set to a text file. \n",
        "\n",
        "You can download `predictions.txt` by going to \n",
        "**View > Table of Contents > Files**\n",
        "\n",
        "Please submit this `predictions.txt` file to Gradescope. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVvjI7ngHuq3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "68c86fbf-b7b3-4ebc-acb1-e05469a96fd4"
      },
      "source": [
        "model.eval()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FancyTagger(\n",
              "  (embeddings): Embedding(500000, 300)\n",
              "  (lstm): LSTM(300, 64, num_layers=2, dropout=0.6, bidirectional=True)\n",
              "  (hidden2tag): Linear(in_features=128, out_features=50, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddSD3-FN9Zzp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert isinstance(model, FancyTagger), 'Please assign your FancyTagger to a variable named model'\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "test_batch_idx, test_batch_lens = test_dataset.get_batches(BATCH_SIZE, vocab, tagset)\n",
        "\n",
        "predictions = []\n",
        "\n",
        "for b in range(len(test_batch_idx)):\n",
        "  logits = model.forward(test_batch_idx[b], test_batch_lens[b])\n",
        "  batch_predictions = torch.argmax(logits, dim=-1).cpu().numpy()\n",
        "\n",
        "  batch_size, _ = test_batch_idx[b].shape\n",
        "\n",
        "  for i in range(batch_size):\n",
        "    preds = batch_predictions[i]\n",
        "    \n",
        "    seq_len = int(test_batch_lens[b][i])\n",
        "    for j in range(seq_len):\n",
        "      predictions.append(int(preds[j]))\n",
        "  \n",
        "\n",
        "with open('predictions.txt', 'w') as f:\n",
        "  for p in predictions:\n",
        "    f.write(str(p) + \"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YDlbvHAhGjf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}